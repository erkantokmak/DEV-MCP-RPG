# ===========================================
# DEV-RPG - CI/CD Analysis Platform
# All ports in range 3200-3300
# Uses Groq API for LLM (free tier, cloud-based)
# ===========================================

services:
  # ===========================================
  # AI ENGINE - Ollama Local LLM (DISABLED - Using Groq API)
  # Uncomment below to use local Ollama instead of Groq
  # ===========================================
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: dev-rpg-ollama
  #   ports:
  #     - "3260:11434"
  #   volumes:
  #     - ollama_models:/root/.ollama
  #   environment:
  #     - OLLAMA_HOST=0.0.0.0
  #   restart: unless-stopped
  #   networks:
  #     - dev-rpg-network

  # ===========================================
  # ORCHESTRATOR - n8n Workflow Engine
  # ===========================================
  n8n:
    image: n8nio/n8n:latest
    container_name: dev-rpg-n8n
    ports:
      - "3220:5678"
    environment:
      - N8N_HOST=0.0.0.0
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - WEBHOOK_URL=http://localhost:3220
      - GENERIC_TIMEZONE=Europe/Istanbul
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=dev_rpg
      - DB_POSTGRESDB_USER=dev_rpg_user
      - DB_POSTGRESDB_PASSWORD=dev_rpg_secret_2026
      - N8N_SECURE_COOKIE=false
    volumes:
      - n8n_data:/home/node/.n8n
      - ./n8n-workflows:/home/node/workflows:ro
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - dev-rpg-network

  # ===========================================
  # DATABASE - PostgreSQL (Port 3231 - çakışma önlendi)
  # ===========================================
  postgres:
    image: postgres:15-alpine
    container_name: dev-rpg-postgres
    ports:
      - "127.0.0.1:3231:5432"
    environment:
      - POSTGRES_DB=dev_rpg
      - POSTGRES_USER=dev_rpg_user
      - POSTGRES_PASSWORD=dev_rpg_secret_2026
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U dev_rpg_user -d dev_rpg"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - dev-rpg-network

  # ===========================================
  # BACKEND API - FastAPI Python
  # ===========================================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: dev-rpg-backend
    ports:
      - "3210:3210"
    environment:
      - DATABASE_URL=postgresql://dev_rpg_user:dev_rpg_secret_2026@postgres:5432/dev_rpg
      - OLLAMA_URL=http://ollama:11434
      - N8N_WEBHOOK_URL=http://n8n:5678
      - LIGHTHOUSE_MCP_URL=http://lighthouse_mcp:8000
      - CODE_QUALITY_MCP_URL=http://code_quality_mcp:8000
      - ARCHITECT_MCP_URL=http://architect_mcp:8000
      - EVENT_LOOP_MCP_URL=http://event_loop_mcp:8000
      - COST_MCP_URL=http://cost_mcp:8000
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - dev-rpg-network

  # ===========================================
  # FRONTEND - React/Vite with Nginx
  # ===========================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - VITE_API_URL=http://localhost:3210
    container_name: dev-rpg-frontend
    ports:
      - "3200:80"
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - dev-rpg-network

  # ===========================================
  # MCP AGENTS - AI-Powered Microservices
  # (Ollama bağımlılığı basitleştirildi - service_started)
  # ===========================================
  
  lighthouse_mcp:
    build:
      context: ./mcp-agents/lighthouse_mcp
      dockerfile: Dockerfile
    container_name: dev-rpg-lighthouse-mcp
    ports:
      - "3201:8000"
    environment:
      - SERVICE_NAME=lighthouse_mcp
      - PORT=8000
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - dev-rpg-network

  code_quality_mcp:
    build:
      context: ./mcp-agents/code_quality_mcp
      dockerfile: Dockerfile
    container_name: dev-rpg-code-quality-mcp
    ports:
      - "3202:8000"
    environment:
      - SERVICE_NAME=code_quality_mcp
      - PORT=8000
      - LLM_PROVIDER=groq
      - GROQ_API_KEY=${GROQ_API_KEY}
      - GROQ_MODEL=llama-3.1-8b-instant
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - dev-rpg-network

  architect_mcp:
    build:
      context: ./mcp-agents/architect_mcp
      dockerfile: Dockerfile
    container_name: dev-rpg-architect-mcp
    ports:
      - "3203:8000"
    environment:
      - SERVICE_NAME=architect_mcp
      - PORT=8000
      - LLM_PROVIDER=groq
      - GROQ_API_KEY=${GROQ_API_KEY}
      - GROQ_MODEL=llama-3.1-8b-instant
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - dev-rpg-network

  event_loop_mcp:
    build:
      context: ./mcp-agents/event_loop_mcp
      dockerfile: Dockerfile
    container_name: dev-rpg-event-loop-mcp
    ports:
      - "3204:8000"
    environment:
      - SERVICE_NAME=event_loop_mcp
      - PORT=8000
      - LLM_PROVIDER=groq
      - GROQ_API_KEY=${GROQ_API_KEY}
      - GROQ_MODEL=llama-3.1-8b-instant
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - dev-rpg-network

  cost_mcp:
    build:
      context: ./mcp-agents/cost_mcp
      dockerfile: Dockerfile
    container_name: dev-rpg-cost-mcp
    ports:
      - "3205:8000"
    environment:
      - SERVICE_NAME=cost_mcp
      - PORT=8000
      - LLM_PROVIDER=groq
      - GROQ_API_KEY=${GROQ_API_KEY}
      - GROQ_MODEL=llama-3.1-8b-instant
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - dev-rpg-network

# ===========================================
# VOLUMES
# ===========================================
volumes:
  # ollama_models:
  #   name: dev-rpg-ollama-models
  postgres_data:
    name: dev-rpg-postgres-data
  n8n_data:
    name: dev-rpg-n8n-data

# ===========================================
# NETWORKS
# ===========================================
networks:
  dev-rpg-network:
    name: dev-rpg-network
    driver: bridge